# -*- coding: utf-8 -*-
"""Assignment2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g-loqI50nxvy16u3QAkkAVAS6LwQ8BwG
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/road_accident_severity.csv')

# Display the first few rows and basic information about the dataset
print(df.head())
print(df.info())

# Preprocess the data
# Convert categorical variables to numerical using LabelEncoder
le = LabelEncoder()
categorical_columns = ['Road_Type', 'Weather_Conditions', 'Light_Conditions', 'Vehicle_Type']
for col in categorical_columns:
    df[col] = le.fit_transform(df[col])

# Define dependent and independent variables
y = df['Accident_Severity']
X = df[['Speed_limit', 'Road_Type', 'Weather_Conditions', 'Light_Conditions', 'Vehicle_Type']]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared Score: {r2}")

# Print the coefficients and their corresponding feature names
coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_})
print(coefficients.sort_values(by='Coefficient', ascending=False))

# Save the model and feature names for future use
joblib.dump(model, 'road_accident_severity_model.joblib')
joblib.dump(X.columns, 'feature_names.joblib')

# Visualize the actual vs predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual Severity')
plt.ylabel('Predicted Severity')
plt.title('Actual vs Predicted Accident Severity')
plt.tight_layout()
plt.savefig('actual_vs_predicted.png')
plt.close()

# Visualize feature importance
plt.figure(figsize=(10, 6))
sns.barplot(x='Coefficient', y='Feature', data=coefficients.sort_values(by='Coefficient', ascending=False))
plt.title('Feature Importance')
plt.tight_layout()
plt.savefig('feature_importance.png')
plt.close()

# Example of using the model for prediction
loaded_model = joblib.load('road_accident_severity_model.joblib')
feature_names = joblib.load('feature_names.joblib')

# Hypothetical set of independent variables
new_data = pd.DataFrame([[60, 1, 1, 1, 2]], columns=feature_names)

# Make a prediction
prediction = loaded_model.predict(new_data)

print(f"Predicted accident severity: {prediction[0]}")

# Function to explain the prediction
def explain_prediction(input_data, prediction):
    explanation = f"For the given input:\n"
    for feature, value in input_data.iloc[0].items():
        explanation += f"- {feature}: {value}\n"
    explanation += f"\nThe predicted accident severity is: {prediction[0]:.2f}\n"
    explanation += "\nThis prediction is based on the linear regression model trained on historical accident data."
    return explanation

print(explain_prediction(new_data, prediction))